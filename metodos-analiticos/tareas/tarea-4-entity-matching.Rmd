---
title: "Tarea 3. Joins por similitud y Entity matching"
output: html_notebook
---


En este ejemplo veremos como usar LSH 
para encontrar registros
que se refieren al mismo elemento pero están en distintas tablas, 
y pueden diferir en cómo están registrados (entity matching). Este también
es un ejemplo

## Datos

Los [datos](https://dbs.uni-leipzig.de/de/research/projects/object_matching/fever/benchmark_datasets_for_entity_resolution) para este ejempo particular trata con dos fuentes bibliográficas (DBLP, ACM)
de artículos y conferencias de cómputo. La carpeta del repositorio
es datos/similitud/entity-matching. **El objetivo es parear las dos fuentes para
identificar artículos que se presenteron en las dos referencias.**


```{r, warning=FALSE, message=FALSE}
library(tidyverse)
acm <- read_csv('../datos/entity_matching/ACM.csv')
dbl <- read_csv('../datos/entity_matching/DBLP2.csv')
```

```{r}
head(acm)
head(dbl)
nrow(acm)
nrow(dbl)
```

**Pregunta 1**: ¿si intentas una aproximación por fuerza bruta, cuántas comparaciones
tendrías que hacer? Si cada tabla contuviera unos 2 millones de documentos, ¿qué tan 
factible sería hacer todas las posibles comparaciones?

## Tejas y hashing

Primero hacemos una limpieza básica (puedes reconsiderar este proceso
más adelante cuando veamos los resultados)_

```{r}
acm_1 <- acm |> select(id, title, authors) |> 
  mutate(texto = paste(title, authors, sep = "    ")) |> 
  mutate(id = as.character(id)) |> 
  mutate(texto = str_to_lower(texto)) |> 
  mutate(texto = str_remove_all(texto, pattern = "[^A-Za-z0-9 -]"))
dbl_1 <- dbl |> select(id, title, authors) |> 
  mutate(texto = paste(title, authors, sep = "    ")) |> 
  mutate(texto = str_to_lower(texto)) |> 
  mutate(texto = str_remove_all(texto, pattern = "[^A-Za-z0-9 -]"))
```

**Pregunta 2**: ¿por qué definimos el texto incluyendo algún espacio en blanco entre título y autor?
¿Qué otra estrategia se te ocurre para convertir en tejas?

**Pregunta 3**: cuántas comparaciones tendrías que hacer si calcularas
la similitud entre todos los posibles pares?

```{r}
# función de las notas
calcular_tejas <- function(x, k = 4, lowercase = FALSE){
  tokenizers::tokenize_character_shingles(x, n = k, lowercase = lowercase,
    simplify = TRUE, strip_non_alpha = FALSE)
}
generar_hash <- function(){
  r <- as.integer(stats::runif(1, 1, 2147483647))
  funcion_hash <- function(tejas){
        digest::digest2int(tejas, seed = r) 
  }
  funcion_hash
}
```

En este caso escogemos 2 hashes,
tejas de tamaño 5, y usamos sólo título y autor.


```{r}
# el siguiente devuelve un objeto con los minhashes calculados
acm_tejas <- acm_1 |> 
  mutate(tejas = map(texto, ~ calcular_tejas(.x, k = 5)))
dbl_tejas <- dbl_1 |> 
  mutate(tejas = map(texto, ~ calcular_tejas(.x, k = 5)))
```

Por ejemplo, para el primer documento tenemos el contenido y los minhashes calculados:

```{r}
acm_tejas$texto[[1]]
dbl_tejas$tejas[[1]]
```

Ahora calculamos minhashes

```{r}
set.seed(88345)
# crear hashes
hashes <- map(1:2, ~ generar_hash())

construir_firmas <- function(hashes, tejas){
  tibble(hash_num = 1:length(hashes), 
         firma = map_int(hashes, \(h) min(h(tejas)))
  )
}

acm_firmas <- acm_tejas |> 
  mutate(firma = map(tejas, ~ construir_firmas(hashes, .x))) |> 
  select(id, firma) |> 
  unnest(firma) |> 
  mutate(cubeta = paste(hash_num, firma, sep = "-")) |> 
  select(id, cubeta)
dbl_firmas <- dbl_tejas |> 
  mutate(firma = map(tejas, ~ construir_firmas(hashes, .x))) |> 
  select(id, firma) |> 
  unnest(firma) |> 
  mutate(cubeta = paste(hash_num, firma, sep = "-")) |> 
  select(id, cubeta)
```

Ahora hacemos una unión por cubetas para obtener nuestros pares candidatos:

```{r}
candidatos_tbl <- inner_join(acm_firmas |> rename(idACM = id), 
                          dbl_firmas |> rename(idDBL = id))
```



## Examinar pares candidatos

Ahora calculamos similitud exacta para candidatos

```{r}
sim_jaccard <- \(a, b)  length(intersect(a, b)) / length(union(a, b))
candidatos_score_tbl <- candidatos_tbl |> 
  left_join(acm_tejas |>
              select(idACM = id, tejas_acm = tejas)) |> 
  left_join(dbl_tejas |> 
              select(idDBL = id, tejas_dbl = tejas)) |> 
  mutate(score = map2_dbl(tejas_acm, tejas_dbl, ~ sim_jaccard(.x, .y))) |> 
  select(-tejas_acm, -tejas_dbl, -cubeta)
candidatos_score_tbl <- candidatos_score_tbl |> 
  unique()
candidatos_score_tbl
```



**Pregunta 4**: explica cómo se calcula la columna *score* en la tabla de candidatos,
y da unos ejemplos.


**Pregunta 5**: ¿Cuántas comparaciones tuviste qué hacer (cálculos de similitud)? Compara con el total
de comparaciones que es posible hacer entre estas dos tablas.


**Pregunta 6**: 
¿Cuántos pares candidatos obtuviste?
Examina algunos elementos con similitud uno o cercana a uno. ¿Se refieren al
mismo artículo en las dos fuentes? 



## Examinar resultados

**Pregunta 8**: Ahora considera los elementos 
con similitud más baja que capturaste. Examina varios casos y concluye
si hay pares que no se refieren al mismo artículo, y por qué.


**Pregunta 9**: propón un punto de corte de similitud para la tabla de arriba, según tus
observaciones de la pregunta anterior.

```{r}
# código filtrando con score > tu_numero, y examinando los elementos
# de similitud más baja
candidatos_filt <- filter(candidatos_score_tbl, score > 0.3)
tail(candidatos_filt)
```

**Pregunta 10**: ¿cuántos pares candidatos obtuviste al final?


## Evaluación de resultados

 Evalúa tus resultados con las respuestas
correctas, que están en la carpeta de los datos.


```{r}
mapping <- read_csv("../datos/entity_matching/DBLP-ACM_perfectMapping.csv")
```


Podemos calcular el número de pares verdaderos que son candidatos (recuperados), el número de pares
candidatos que son candidatos pero no son pares verdaderos, por ejemplo:

```{r}
mapping <- mapping |> mutate(idACM = as.character(idACM))
ambos <- inner_join(candidatos_filt, mapping)
nrow(candidatos_filt)
nrow(ambos)
```

*Pregunta 11*: ¿Hubiera funcionado igualmente bien hacer un join usando 
autores o título en lugar de este join por similitud?

*Pregunta 12 *: Evalúa precisión y recall de tu método. Para distintas aplicaciones que te
puedas imaginar, ¿qué tan buenos son estos resultados? ¿Qué consideras
mejor en este punto, tener precisión o recall alto? 

```{r}
#precision <- 
#precision
#recall <- 
#recall
```


## Análisis de errores

Considera algunos casos que fallamos en recuperar como candidatos. Examina algunos
de los siguientes pares:

```{r}
anti_join(mapping, candidatos_filt) 
```

También puedes examinar falsos positivos:

```{r}
anti_join(candidatos_filt, mapping) 
```


**Pregunta 11**: Considerando estos errores, ¿qué se te ocurre para mejorar el método?
